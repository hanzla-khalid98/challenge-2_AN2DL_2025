{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Artificial Neural Networks and Deep Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **Lecture 6 (BONUS): Images in Python**\n",
        "\n",
        "<img src=\"https://lh3.googleusercontent.com/LETOJEN4d0cH1kSdZ1mZ4eUKtU5pg0gA8uIEC3oVGkhB0Wdo9VvFxYW957mdDohI32ssTgs19Snf25ON-sTL9aI8oTjLlzIsEvU-jD3aX12Yi6tVUo7Bepz2H0Tzvsyx920Dpd7R\" width=\"500\"/>"
      ],
      "metadata": {
        "id": "4m76usE6bthZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è **Libraries Import**"
      ],
      "metadata": {
        "id": "wqEcNLzwcSzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "Y6ucpD8hOkXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì∏ **Image Loading**"
      ],
      "metadata": {
        "id": "v8nxKqiBe01O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a sample image\n",
        "url = \"https://i.pinimg.com/736x/31/f8/8d/31f88dd60329078bac90b7f8e59bdd53.jpg\"\n",
        "response = requests.get(url)\n",
        "img_pil = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "# Convert to numpy array\n",
        "img = np.array(img_pil)\n",
        "\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Data type: {img.dtype}\")\n",
        "print(f\"Value range: [{img.min()}, {img.max()}]\")\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UB1GI0LkeOjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width, channels = img.shape\n",
        "print(f\"Height: {height} pixels\")\n",
        "print(f\"Width: {width} pixels\")\n",
        "print(f\"Channels: {channels}\")\n",
        "\n",
        "# Visualize a single pixel's values\n",
        "pixel_y, pixel_x = 100, 100\n",
        "pixel_values = img[pixel_y, pixel_x]\n",
        "print(f\"\\nPixel at ({pixel_x}, {pixel_y}): RGB = {pixel_values}\")\n",
        "print(f\"Image content: {img.nbytes / 1e6:.2f}MB\")"
      ],
      "metadata": {
        "id": "_OXzC6R9eOhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® **Color Channels and Library Conventions**"
      ],
      "metadata": {
        "id": "JzyosDWZfPDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "# Original\n",
        "axes[0, 0].imshow(img)\n",
        "axes[0, 0].set_title(\"Original\")\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "# Individual channels\n",
        "channel_names = ['Red', 'Green', 'Blue']\n",
        "for i, name in enumerate(channel_names):\n",
        "    img_channel = np.zeros_like(img)\n",
        "    img_channel[:, :, i] = img[:, :, i]\n",
        "    axes[0, i+1].imshow(img_channel)\n",
        "    axes[0, i+1].set_title(f\"{name} Channel\")\n",
        "    axes[0, i+1].axis('off')\n",
        "\n",
        "# Channel swapping effects\n",
        "img_gbr = img[:, :, [1, 2, 0]]  # Green, Blue, Red\n",
        "img_brg = img[:, :, [2, 0, 1]]  # Blue, Red, Green\n",
        "img_grb = img[:, :, [1, 0, 2]]  # Green, Red, Blue\n",
        "\n",
        "axes[1, 0].imshow(img)\n",
        "axes[1, 0].set_title(\"Original RGB\")\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(img_gbr)\n",
        "axes[1, 1].set_title(\"GBR\")\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "axes[1, 2].imshow(img_brg)\n",
        "axes[1, 2].set_title(\"BRG\")\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "axes[1, 3].imshow(img_grb)\n",
        "axes[1, 3].set_title(\"GRB\")\n",
        "axes[1, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7vzw4B8bfz8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the same image with OpenCV\n",
        "img_pil.save('temp_img.jpg')\n",
        "img_cv2 = cv2.imread('temp_img.jpg')\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# RGB (PIL/Matplotlib convention)\n",
        "axes[0].imshow(img)\n",
        "axes[0].set_title(\"RGB (PIL/Matplotlib)\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# BGR (OpenCV convention) - displayed incorrectly\n",
        "axes[1].imshow(img_cv2)\n",
        "axes[1].set_title(\"BGR displayed as RGB\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "# BGR converted to RGB for correct display\n",
        "img_cv2_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "axes[2].imshow(img_cv2_rgb)\n",
        "axes[2].set_title(\"BGR converted to RGB (Correct)\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dd71QQL3eOe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different grayscale conversion methods\n",
        "gray_avg = np.mean(img, axis=2)\n",
        "\n",
        "# Weighted/Luminosity - matches human perception\n",
        "# Human eyes are most sensitive to green, then red, then blue\n",
        "gray_weighted = 0.299 * img[:, :, 0] + 0.587 * img[:, :, 1] + 0.114 * img[:, :, 2]\n",
        "gray_pil = img_pil.convert('L')\n",
        "gray_pil_array = np.array(gray_pil)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "axes[0].imshow(img)\n",
        "axes[0].set_title(\"Original Color\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(gray_avg, cmap='gray')\n",
        "axes[1].set_title(\"Simple Average\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(gray_weighted, cmap='gray')\n",
        "axes[2].set_title(\"Weighted (Luminosity)\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "axes[3].imshow(gray_pil_array, cmap='gray')\n",
        "axes[3].set_title(\"PIL Conversion\")\n",
        "axes[3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Color image shape: {img.shape}\")\n",
        "print(f\"Grayscale image shape: {gray_weighted.shape}\")"
      ],
      "metadata": {
        "id": "zF2DeY9PeOcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü¶∏ **Image Transformations**"
      ],
      "metadata": {
        "id": "bRDiGFgehi0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = img_pil\n",
        "\n",
        "# Flip operations\n",
        "flip_horizontal = np.fliplr(img)\n",
        "flip_vertical = np.flipud(img)\n",
        "\n",
        "# Rotation using array indexing\n",
        "rotate_90 = np.rot90(img, k=1)\n",
        "rotate_180 = np.rot90(img, k=2)\n",
        "rotate_270 = np.rot90(img, k=3)\n",
        "\n",
        "# Transpose\n",
        "transpose = gray_weighted.T\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "axes[0, 0].imshow(img)\n",
        "axes[0, 0].set_title(\"Original\")\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(flip_horizontal)\n",
        "axes[0, 1].set_title(\"Horizontal Flip\")\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].imshow(flip_vertical)\n",
        "axes[0, 2].set_title(\"Vertical Flip\")\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "axes[0, 3].imshow(transpose, cmap='gray')\n",
        "axes[0, 3].set_title(\"Transpose\")\n",
        "axes[0, 3].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(img)\n",
        "axes[1, 0].set_title(\"Original\")\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(rotate_90)\n",
        "axes[1, 1].set_title(\"Rotate 90¬∞\")\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "axes[1, 2].imshow(rotate_180)\n",
        "axes[1, 2].set_title(\"Rotate 180¬∞\")\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "axes[1, 3].imshow(rotate_270)\n",
        "axes[1, 3].set_title(\"Rotate 270¬∞\")\n",
        "axes[1, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sUWy2MnSeOaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßÆ **Convolutions**"
      ],
      "metadata": {
        "id": "IOQpg3VdiMlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve2d(image, kernel, apply_to_red=True, apply_to_green=True, apply_to_blue=True):\n",
        "    image = np.array(image)\n",
        "    kernel = np.flipud(np.fliplr(kernel))  # Flip kernel for proper convolution\n",
        "    k_height, k_width = kernel.shape\n",
        "\n",
        "    pad_h = k_height // 2\n",
        "    pad_w = k_width // 2\n",
        "\n",
        "    if len(image.shape) == 2:\n",
        "        image = image[:, :, np.newaxis]\n",
        "        single_channel = True\n",
        "    else:\n",
        "        single_channel = False\n",
        "\n",
        "    padded = np.pad(image,\n",
        "                    ((pad_h, pad_h), (pad_w, pad_w), (0, 0)),\n",
        "                    mode='edge')\n",
        "\n",
        "    output = np.zeros_like(image)\n",
        "\n",
        "    num_channels = image.shape[2]\n",
        "    apply_flags = [apply_to_red, apply_to_green, apply_to_blue]\n",
        "\n",
        "    for c in range(num_channels):\n",
        "        if single_channel or (c < 3 and apply_flags[c]):\n",
        "            for i in range(image.shape[0]):\n",
        "                for j in range(image.shape[1]):\n",
        "                    region = padded[i:i+k_height, j:j+k_width, c]\n",
        "                    output[i, j, c] = np.sum(kernel * region)\n",
        "        else:\n",
        "            output[:, :, c] = image[:, :, c]\n",
        "\n",
        "    if single_channel:\n",
        "        output = output[:, :, 0]\n",
        "\n",
        "    # Normalize output\n",
        "    min_val = np.min(output)\n",
        "    max_val = np.max(output)\n",
        "    return (output - min_val) / (max_val - min_val) if min_val != max_val else output"
      ],
      "metadata": {
        "id": "KUfo2N_vho7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution on a Grayscale Image"
      ],
      "metadata": {
        "id": "6DANh08CybFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Half the resolution to make it faster\n",
        "img = np.array(gray_weighted)\n",
        "img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))\n",
        "\n",
        "# Custom kernel - sharpen\n",
        "custom_kernel = np.array([\n",
        "    [0, -1, 0],\n",
        "    [-1, 5, -1],\n",
        "    [0, -1, 0]\n",
        "])\n",
        "\n",
        "result_custom = convolve2d(img, custom_kernel)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(custom_kernel, vmin=-1, vmax=5)\n",
        "axes[1].set_title(\"Sharpen Kernel\")\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axes[1].text(j, i, f'{custom_kernel[i, j]}',\n",
        "                    ha='center', va='center', fontsize=12)\n",
        "axes[1].set_xticks([])\n",
        "axes[1].set_yticks([])\n",
        "\n",
        "axes[2].imshow(result_custom, cmap='gray')\n",
        "axes[2].set_title(\"Sharpened Image\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5refoEurho5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution on All Color Channels"
      ],
      "metadata": {
        "id": "8GQSnafTye9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(img_pil)\n",
        "img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))\n",
        "\n",
        "# Custom kernel - sharpen\n",
        "custom_kernel = np.array([\n",
        "    [0, -1, 0],\n",
        "    [-1, 5, -1],\n",
        "    [0, -1, 0]\n",
        "])\n",
        "\n",
        "result_custom = convolve2d(img, custom_kernel)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(custom_kernel, vmin=-1, vmax=5)\n",
        "axes[1].set_title(\"Sharpen Kernel\")\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axes[1].text(j, i, f'{custom_kernel[i, j]}',\n",
        "                    ha='center', va='center', fontsize=12)\n",
        "axes[1].set_xticks([])\n",
        "axes[1].set_yticks([])\n",
        "\n",
        "axes[2].imshow(result_custom, cmap='gray')\n",
        "axes[2].set_title(\"Sharpened Image\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YvMQhR4myFIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution on a Single Color Channel"
      ],
      "metadata": {
        "id": "UHV-b3dbyn6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(img_pil)\n",
        "img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))\n",
        "\n",
        "# Custom kernel - sharpen\n",
        "custom_kernel = np.array([\n",
        "    [0, -1, 0],\n",
        "    [-1, 5, -1],\n",
        "    [0, -1, 0]\n",
        "])\n",
        "\n",
        "result_custom = convolve2d(img, custom_kernel, apply_to_blue=False, apply_to_green=False)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(custom_kernel, vmin=-1, vmax=5)\n",
        "axes[1].set_title(\"Sharpen Kernel\")\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axes[1].text(j, i, f'{custom_kernel[i, j]}',\n",
        "                    ha='center', va='center', fontsize=12)\n",
        "axes[1].set_xticks([])\n",
        "axes[1].set_yticks([])\n",
        "\n",
        "axes[2].imshow(result_custom, cmap='gray')\n",
        "axes[2].set_title(\"Sharpened Image\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0jKZA-IHynMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Convolutions"
      ],
      "metadata": {
        "id": "ng36a6-Mywu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define standard kernels\n",
        "kernels = {\n",
        "    'Identity': np.array([[0, 0, 0],\n",
        "                         [0, 1, 0],\n",
        "                         [0, 0, 0]]),\n",
        "\n",
        "    'Box Blur': np.ones((3, 3)) / 9,\n",
        "\n",
        "    'Gaussian Blur': np.array([[1, 2, 1],\n",
        "                               [2, 4, 2],\n",
        "                               [1, 2, 1]]) / 16,\n",
        "\n",
        "    'Edge (Laplacian)': np.array([[0, 1, 0],\n",
        "                                  [1, -4, 1],\n",
        "                                  [0, 1, 0]]),\n",
        "\n",
        "    'Edge (Laplacian v2)': np.array([[-1, -1, -1],\n",
        "                                     [-1, 8, -1],\n",
        "                                     [-1, -1, -1]]),\n",
        "\n",
        "    'Sobel X': np.array([[-1, 0, 1],\n",
        "                         [-2, 0, 2],\n",
        "                         [-1, 0, 1]]),\n",
        "\n",
        "    'Sobel Y': np.array([[-1, -2, -1],\n",
        "                         [0, 0, 0],\n",
        "                         [1, 2, 1]]),\n",
        "\n",
        "    'Emboss': np.array([[-2, -1, 0],\n",
        "                        [-1, 1, 1],\n",
        "                        [0, 1, 2]])\n",
        "}\n",
        "\n",
        "img = np.array(gray_weighted)\n",
        "img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))\n",
        "\n",
        "# Apply kernels\n",
        "results = {}\n",
        "for i, (name, kernel) in enumerate(kernels.items()):\n",
        "    print(f\"[{i+1}/{len(kernels)}] Applying {name} kernel...\")\n",
        "    results[name] = convolve2d(img.astype(float), kernel)"
      ],
      "metadata": {
        "id": "wlO4Y9F4w2wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "axes = axes.ravel()\n",
        "\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title(\"Original\", fontsize=12)\n",
        "axes[0].axis('off')\n",
        "\n",
        "for idx, (name, result) in enumerate(results.items(), 1):\n",
        "    axes[idx].imshow(result, cmap='gray')\n",
        "    axes[idx].set_title(name, fontsize=12)\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3jd9Rptdw9VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Sobel X and Y for edge magnitude\n",
        "sobel_x = results['Sobel X']\n",
        "sobel_y = results['Sobel Y']\n",
        "sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "axes[0].imshow(img, cmap='gray')\n",
        "axes[0].set_title(\"Original\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(sobel_x, cmap='gray')\n",
        "axes[1].set_title(\"Sobel X (Vertical Edges)\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(sobel_y, cmap='gray')\n",
        "axes[2].set_title(\"Sobel Y (Horizontal Edges)\")\n",
        "axes[2].axis('off')\n",
        "\n",
        "axes[3].imshow(sobel_magnitude, cmap='gray')\n",
        "axes[3].set_title(\"Sobel Magnitude (All Edges)\")\n",
        "axes[3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VcIVWBOezi3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying the Same Convolution Multiple Times"
      ],
      "metadata": {
        "id": "DO3JWARI3LuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.array(gray_weighted)\n",
        "img = cv2.resize(img, (img.shape[1] // 2, img.shape[0] // 2))\n",
        "\n",
        "kernel = np.array([[-2, 1, 3],\n",
        "                   [1, 1, 1],\n",
        "                   [3, 1, -2]])\n",
        "\n",
        "\n",
        "def apply_kernel_iterations(img, kernel, iterations=5):\n",
        "    output = img.copy()\n",
        "\n",
        "    for i in range(iterations):\n",
        "        print(f\"[{i+1}/{iterations}] Applying kernel iteration...\")\n",
        "        output = convolve2d(output, kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "processed = apply_kernel_iterations(img, kernel, iterations=1)\n",
        "\n",
        "# Display result\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Processed\")\n",
        "plt.imshow(processed, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KOeckPop1Tyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "##### Connect with us:\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"14\"> **LinkedIn:**  [AIRLab Polimi](https://www.linkedin.com/company/airlab-polimi/)\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"14\"> **Instagram:** [airlab_polimi](https://www.instagram.com/airlab_polimi/)\n",
        "\n",
        "##### Contributors:\n",
        "- **Eugenio Lomurno**: eugenio.lomurno@polimi.it\n",
        "- **Alberto Archetti**: alberto.archetti@polimi.it\n",
        "- **Roberto Basla**: roberto.basla@polimi.it\n",
        "- **Carlo Sgaravatti**: carlo.sgaravatti@polimi.it\n",
        "\n",
        "```\n",
        "   Copyright 2025 Eugenio Lomurno, Alberto Archetti, Roberto Basla, Carlo Sgaravatti\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```\n"
      ],
      "metadata": {
        "id": "iAFY7-o46mnm"
      }
    }
  ]
}