{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Artificial Neural Networks and Deep Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## **Lecture 6: Convolutional Neural Networks**\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ffjpWwLSS5XwEW2GVW0D_hpwgSw1Mf3g\" width=\"500\"/>"
      ],
      "metadata": {
        "id": "YuubT0VoTWci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üåê **Google Drive Connection**"
      ],
      "metadata": {
        "id": "_RuOH2URTeYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l_z63BkTBmY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "current_dir = \"/gdrive/My\\\\ Drive/[2025-2026]\\\\ AN2DL/Lecture\\\\ 6\"\n",
        "%cd $current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è **Libraries Import**"
      ],
      "metadata": {
        "id": "WyBF2ZzWT5eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Configurazione di TensorBoard e directory\n",
        "logs_dir = \"tensorboard\"\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p models\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "PsXrGl9qUNU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è≥ **Data Loading**"
      ],
      "metadata": {
        "id": "W0AX9_UhT5bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory for dataset storage\n",
        "data_dir = './data'\n",
        "\n",
        "# Load CIFAR10 training and validation data as PIL Images\n",
        "train_val_pil = datasets.CIFAR10(\n",
        "    root=data_dir,\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=None\n",
        ")\n",
        "\n",
        "# Load CIFAR10 test data\n",
        "test_pil = datasets.CIFAR10(\n",
        "    root=data_dir,\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=None\n",
        ")\n",
        "\n",
        "# Extract NumPy arrays: .data is (N, H, W, C), .targets contains class indices\n",
        "X_train_val = train_val_pil.data\n",
        "y_train_val = np.array(train_val_pil.targets)\n",
        "X_test = test_pil.data\n",
        "y_test = np.array(test_pil.targets)\n",
        "\n",
        "# Reshape labels to column vectors (N, 1)\n",
        "y_train_val = y_train_val.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "# CIFAR10 class labels\n",
        "labels = {\n",
        "    0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer',\n",
        "    5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'\n",
        "}\n",
        "\n",
        "# Extract ordered list of class names\n",
        "unique_labels = list(labels.values())"
      ],
      "metadata": {
        "id": "LzbQXJ43Ui1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîé **Exploration and Data Analysis**"
      ],
      "metadata": {
        "id": "9rJTsFDEVlxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the loaded datasets\n",
        "print(\"Training-Validation Data Shape:\", X_train_val.shape)\n",
        "print(\"Training-Validation Label Shape:\", y_train_val.shape)\n",
        "print(\"Test Data Shape:\", X_test.shape)\n",
        "print(\"Test Label Shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "J5l8XZtWWJT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample of images from the training-validation dataset\n",
        "num_img = 10\n",
        "random_indices = random.sample(range(len(X_train_val)), num_img)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_img, figsize=(20, 20))\n",
        "\n",
        "# Iterate through the selected number of images\n",
        "for i, idx in enumerate(random_indices):\n",
        "    ax = axes[i % num_img]\n",
        "    ax.imshow(np.squeeze(X_train_val[idx]), vmin=0., vmax=1.)\n",
        "    ax.set_title(f'{labels[y_train_val[idx][0]]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "# Adjust layout and display the images\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1buYBKHwWNWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the target\n",
        "print('Counting occurrences of target classes:')\n",
        "print(pd.DataFrame(y_train_val, columns=['digit'])['digit'].value_counts())"
      ],
      "metadata": {
        "id": "SDNxrPdtWQBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ **Data Preprocessing**"
      ],
      "metadata": {
        "id": "rBugL1XVWTwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data to the range [0, 1]\n",
        "X_train_val = (X_train_val / 255).astype('float32')\n",
        "X_test = (X_test / 255).astype('float32')"
      ],
      "metadata": {
        "id": "DkYawvIhWUu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets, maintaining class distribution\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=SEED, test_size=0.1, stratify=y_train_val)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Training Label Shape:\", y_train.shape)\n",
        "print(\"Validation Data Shape:\", X_val.shape)\n",
        "print(\"Validation Label Shape:\", y_val.shape)"
      ],
      "metadata": {
        "id": "XANgFLMiWkRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape based on the training data\n",
        "input_shape = (X_train.shape[3], X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# Define the number of classes based on the categorical labels\n",
        "num_classes = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "q2ugHhLPXQkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
        "train_ds = TensorDataset(torch.from_numpy(X_train).permute(0, 3, 1, 2), torch.from_numpy(y_train).squeeze())\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val).permute(0, 3, 1, 2), torch.from_numpy(y_val).squeeze())\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test).permute(0, 3, 1, 2), torch.from_numpy(y_test).squeeze())"
      ],
      "metadata": {
        "id": "puE6OQqsXR8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size, which is the number of samples in each batch\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "D6HmbwFLXR5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )"
      ],
      "metadata": {
        "id": "JLasSIoqWUsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders with different settings for each phase\n",
        "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "XWFSxRLsXR3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch from the training data loader\n",
        "for xb, yb in train_loader:\n",
        "    print(\"Features batch shape:\", xb.shape)\n",
        "    print(\"Labels batch shape:\", yb.shape)\n",
        "    break # Stop after getting one batch"
      ],
      "metadata": {
        "id": "yQVfh4FhXR0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è **Convolutional Neural Networks**\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/format:webp/1*oB3S5yHHhvougJkPXuc8og.gif\" width=\"500\">"
      ],
      "metadata": {
        "id": "9dkPFyGwWrqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßÆ **Network Parameters**"
      ],
      "metadata": {
        "id": "l-21zAjtXibx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training epochs\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 1000\n",
        "PATIENCE = 50\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0.2         # Dropout probability\n",
        "L1_LAMBDA = 0            # L1 penalty\n",
        "L2_LAMBDA = 0            # L2 penalty\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Print the defined parameters\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Batch Size:\", BATCH_SIZE)\n",
        "print(\"Learning Rare:\", LEARNING_RATE)\n",
        "print(\"Dropout Rate:\", DROPOUT_RATE)\n",
        "print(\"L1 Penalty:\", L1_LAMBDA)\n",
        "print(\"L2 Penalty:\", L2_LAMBDA)"
      ],
      "metadata": {
        "id": "LjOn3ruBWxwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è **Simple CNN**"
      ],
      "metadata": {
        "id": "F5GaVNYUNIHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/345788674/figure/fig1/AS:957248478117889@1605237230738/Overview-and-details-of-a-convolutional-neural-network-CNN-architecture-for-image_W640.jpg\" width=\"400\">"
      ],
      "metadata": {
        "id": "CyLOpYKjYHy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Architecture parameters\n",
        "# Number of convolutional blocks\n",
        "NUM_BLOCKS = 2\n",
        "\n",
        "# Number of conv layers per block\n",
        "CONVS_PER_BLOCK = 1\n",
        "\n",
        "# Use strided convolutions instead of pooling\n",
        "USE_STRIDE = False\n",
        "\n",
        "# Stride value when USE_STRIDE is True\n",
        "STRIDE_VALUE = 2\n",
        "\n",
        "# Padding size\n",
        "PADDING_SIZE = 1\n",
        "\n",
        "# Pooling size when USE_STRIDE is False\n",
        "POOL_SIZE = 2\n",
        "\n",
        "# Number of channels in first block\n",
        "INITIAL_CHANNELS = 32\n",
        "\n",
        "# Channel multiplication factor between blocks\n",
        "CHANNEL_MULTIPLIER = 2\n",
        "\n",
        "print(\"Num Blocks:\", NUM_BLOCKS)\n",
        "print(\"Convs per Block:\", CONVS_PER_BLOCK)\n",
        "print(\"Use Stride:\", USE_STRIDE)\n",
        "print(\"Stride Value:\", STRIDE_VALUE)\n",
        "print(\"Padding Size:\", PADDING_SIZE)\n",
        "print(\"Pool Size:\", POOL_SIZE)\n",
        "print(\"Initial Channels:\", INITIAL_CHANNELS)\n",
        "print(\"Channel Multiplier:\", CHANNEL_MULTIPLIER)"
      ],
      "metadata": {
        "id": "jgnta1SKP21T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single convolutional block with multiple conv layers, ReLU and pooling/stride\n",
        "class VanillaCNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_convs=1, use_stride=False, stride_value=2, padding_size=1, pool_size=2):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # First convolution: in_channels -> out_channels\n",
        "        if num_convs == 1:\n",
        "            # Single conv: apply stride here if use_stride is True\n",
        "            stride = stride_value if use_stride else 1\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding_size, stride=stride))\n",
        "        else:\n",
        "            # Multiple convs: first one always has stride=1\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1))\n",
        "\n",
        "            # Intermediate convolutions (all with stride=1)\n",
        "            for i in range(1, num_convs - 1):\n",
        "                layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1))\n",
        "\n",
        "            # Last convolution: apply stride here if use_stride is True\n",
        "            stride = stride_value if use_stride else 1\n",
        "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding_size, stride=stride))\n",
        "\n",
        "        # ReLU activation\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        # Pooling only if not using stride for spatial reduction\n",
        "        if not use_stride:\n",
        "            layers.append(nn.MaxPool2d(kernel_size=pool_size, stride=pool_size))\n",
        "\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "# Convolutional Neural Network architecture for CIFAR10 classification\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape=(3,32,32), num_classes=10, dropout_rate=DROPOUT_RATE,\n",
        "                 num_blocks=NUM_BLOCKS, convs_per_block=CONVS_PER_BLOCK,\n",
        "                 use_stride=USE_STRIDE, stride_value=STRIDE_VALUE, padding_size=PADDING_SIZE, pool_size=POOL_SIZE,\n",
        "                 initial_channels=INITIAL_CHANNELS, channel_multiplier=CHANNEL_MULTIPLIER):\n",
        "        super().__init__()\n",
        "\n",
        "        # Build convolutional blocks\n",
        "        blocks = []\n",
        "        in_channels = input_shape[0]\n",
        "        out_channels = initial_channels\n",
        "\n",
        "        for i in range(num_blocks):\n",
        "            blocks.append(VanillaCNNBlock(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                num_convs=convs_per_block,\n",
        "                use_stride=use_stride,\n",
        "                stride_value=stride_value,\n",
        "                padding_size=padding_size,\n",
        "                pool_size=pool_size\n",
        "            ))\n",
        "\n",
        "            # Prepare for next block: increase channels\n",
        "            in_channels = out_channels\n",
        "            out_channels = out_channels * channel_multiplier\n",
        "\n",
        "        self.features = nn.Sequential(*blocks)\n",
        "\n",
        "        # Calculate flattened size after all blocks using a dummy forward pass\n",
        "        # This approach is robust and works with any configuration of padding, stride, and pooling\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, *input_shape)\n",
        "            dummy_output = self.features(dummy_input)\n",
        "            flattened_size = dummy_output.view(1, -1).shape[1]\n",
        "\n",
        "        # Classification head: flatten features and apply dropout before final layer\n",
        "        self.classifier_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(flattened_size, num_classes)\n",
        "        )\n",
        "\n",
        "    # Forward pass through the network\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VnHo5wAFWUqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate CNN model and move to computing device (CPU/GPU)\n",
        "cnn_model = CNN(\n",
        "    input_shape,\n",
        "    num_classes,\n",
        "    num_blocks=NUM_BLOCKS,\n",
        "    convs_per_block=CONVS_PER_BLOCK,\n",
        "    use_stride=USE_STRIDE,\n",
        "    stride_value=STRIDE_VALUE,\n",
        "    padding_size=PADDING_SIZE,\n",
        "    pool_size=POOL_SIZE,\n",
        "    initial_channels=INITIAL_CHANNELS,\n",
        "    channel_multiplier=CHANNEL_MULTIPLIER\n",
        "    ).to(device)\n",
        "\n",
        "# Display model architecture summary\n",
        "summary(cnn_model, input_size=input_shape)"
      ],
      "metadata": {
        "id": "QBd8JuIcWUnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up TensorBoard logging and save model architecture\n",
        "experiment_name = \"cnn\"\n",
        "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
        "x = torch.randn(1, input_shape[0], input_shape[1], input_shape[2]).to(device)\n",
        "writer.add_graph(cnn_model, x)\n",
        "\n",
        "# Define optimizer with L2 regularization\n",
        "optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
        "\n",
        "# Enable mixed precision training for GPU acceleration\n",
        "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
      ],
      "metadata": {
        "id": "0yQNlR4Tgeqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† **Model Training**"
      ],
      "metadata": {
        "id": "KFy8f-BYgN1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize best model tracking variables\n",
        "best_model = None\n",
        "best_performance = float('-inf')"
      ],
      "metadata": {
        "id": "G638yTlZfuVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 and L2 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1"
      ],
      "metadata": {
        "id": "kFxZVvP6fuTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ],
      "metadata": {
        "id": "BrTXNDvzfuQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Check if the tensor is not empty before adding a histogram\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                # Check if the gradient tensor is not empty before adding a histogram\n",
        "                if param.grad.numel() > 0:\n",
        "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
        "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
      ],
      "metadata": {
        "id": "fm7TOAa5fuNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    print(f\"Training {epochs} epochs...\")\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement:\n",
        "                best_metric = current_metric\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
        "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0:\n",
        "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history"
      ],
      "metadata": {
        "id": "k5BeC6FffuKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train model and track training history\n",
        "cnn_model, training_history = fit(\n",
        "    model=cnn_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    writer=writer,\n",
        "    verbose=1,\n",
        "    experiment_name=\"cnn\",\n",
        "    patience=20\n",
        "    )\n",
        "\n",
        "# Update best model if current performance is superior\n",
        "if training_history['val_f1'][-1] > best_performance:\n",
        "    best_model = cnn_model\n",
        "    best_performance = training_history['val_f1'][-1]"
      ],
      "metadata": {
        "id": "tTOc-uJWfuIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Hitory\n",
        "# Create a figure with two side-by-side subplots (two columns)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
        "\n",
        "# Plot of training and validation loss on the first axis\n",
        "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
        "ax1.set_title('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Plot of training and validation accuracy on the second axis\n",
        "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
        "ax2.set_title('F1 Score')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.85)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4YQjBvXgfuFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Confusion Matrix\n",
        "# Collect predictions and ground truth labels\n",
        "val_preds, val_targets = [], []\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions\n",
        "        logits = cnn_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        val_preds.append(preds)\n",
        "        val_targets.append(yb.numpy())\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "val_preds = np.concatenate(val_preds)\n",
        "val_targets = np.concatenate(val_targets)\n",
        "\n",
        "# Calculate overall validation metrics\n",
        "val_acc = accuracy_score(val_targets, val_preds)\n",
        "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
        "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
        "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
        "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
        "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
        "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
        "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix for detailed error analysis\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix ‚Äî Validation Set')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-dgEZ83efuDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Activation visualisation\n",
        "def get_activation(name):\n",
        "    \"\"\"Creates a hook function to capture and store layer outputs.\"\"\"\n",
        "    def hook(model, input, output):\n",
        "        activations[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "\n",
        "def find_last_conv_layer(model):\n",
        "    \"\"\"\n",
        "    Identifies the final Conv2D layer in the model architecture.\n",
        "    \"\"\"\n",
        "    last_conv_name = None\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            last_conv_name = name\n",
        "\n",
        "    if last_conv_name is None:\n",
        "        raise ValueError(\"No Conv2D layer found in the model.\")\n",
        "    return last_conv_name\n",
        "\n",
        "\n",
        "def visualize(model, X, y, unique_labels, num_images=50, display_activations=True, display_all_conv_layers=False):\n",
        "    \"\"\"\n",
        "    Visualises model predictions and internal activations for a random test image.\n",
        "    Uses PyTorch hooks to extract intermediate layer outputs.\n",
        "\n",
        "    Args:\n",
        "        display_all_conv_layers: If True, shows all conv layers. If False, shows only last conv of each block.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Select Image and Prepare Tensor ---\n",
        "\n",
        "    # Randomly select an image from the dataset\n",
        "    image_idx = np.random.randint(0, num_images)\n",
        "    img_np = X[image_idx]\n",
        "    label_np = y[image_idx]\n",
        "\n",
        "    # Convert NumPy array to PyTorch tensor with correct dimensions\n",
        "    # Transform from (H, W, C) to (N, C, H, W) format\n",
        "    img_tensor = torch.from_numpy(img_np)\n",
        "    img_tensor = img_tensor.permute(2, 0, 1)\n",
        "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    # --- 2. Register Hooks and Make Prediction ---\n",
        "\n",
        "    # Clear previous activations\n",
        "    activations.clear()\n",
        "\n",
        "    # Attach forward hooks to convolutional layers\n",
        "    hooks = []\n",
        "    conv_names = []\n",
        "\n",
        "    # Iterate through all blocks in the features Sequential\n",
        "    for block_idx, block in enumerate(model.features):\n",
        "        # Find all Conv2d layers in this block\n",
        "        conv_layers_in_block = []\n",
        "        for layer_idx, layer in enumerate(block.block):\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                conv_layers_in_block.append((layer_idx, layer))\n",
        "\n",
        "        # Register hooks based on display_all_conv_layers flag\n",
        "        if display_all_conv_layers:\n",
        "            # Register hook for every Conv2d layer\n",
        "            for layer_idx, conv_layer in conv_layers_in_block:\n",
        "                hook_name = f'block{block_idx}_conv{layer_idx}'\n",
        "                conv_names.append(hook_name)\n",
        "                hooks.append(conv_layer.register_forward_hook(get_activation(hook_name)))\n",
        "        else:\n",
        "            # Register hook only for the last Conv2d layer in this block\n",
        "            if conv_layers_in_block:\n",
        "                layer_idx, conv_layer = conv_layers_in_block[-1]\n",
        "                hook_name = f'block{block_idx}_conv{layer_idx}'\n",
        "                conv_names.append(hook_name)\n",
        "                hooks.append(conv_layer.register_forward_hook(get_activation(hook_name)))\n",
        "\n",
        "    # Generate prediction with gradient tracking disabled\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(img_tensor)\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Remove hooks after forward pass\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # Extract predicted class and confidence\n",
        "    predictions = probabilities.cpu().numpy()\n",
        "    class_int = np.argmax(predictions[0])\n",
        "    class_str = unique_labels[class_int]\n",
        "\n",
        "    # Extract true class (handle both one-hot encoded and integer labels)\n",
        "    if label_np.ndim > 0 and len(label_np) > 1:\n",
        "        # One-hot encoded\n",
        "        true_class_int = np.argmax(label_np)\n",
        "    else:\n",
        "        # Already an integer index\n",
        "        true_class_int = int(label_np)\n",
        "    true_class_str = unique_labels[true_class_int]\n",
        "\n",
        "    # --- 3. Plot Image and Prediction Bar ---\n",
        "\n",
        "    # Create figure with custom layout\n",
        "    fig = plt.figure(constrained_layout=True, figsize=(16, 4))\n",
        "    gs = gridspec.GridSpec(1, 2, figure=fig, width_ratios=[1.5, 1.5], wspace=0)\n",
        "\n",
        "    # Display original image with true label\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax1.set_title(f\"True class: {true_class_str}\", loc='left')\n",
        "    if img_np.shape[-1] == 1:\n",
        "        ax1.imshow(np.squeeze(img_np), cmap='bone', vmin=0., vmax=1.)\n",
        "    else:\n",
        "        ax1.imshow(np.squeeze(img_np), vmin=0., vmax=1.)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Display class probability distribution\n",
        "    ax2 = fig.add_subplot(gs[1])\n",
        "    ax2.barh(unique_labels, np.squeeze(predictions, axis=0), color=plt.get_cmap('tab10').colors)\n",
        "    ax2.set_title(f\"Predicted class: {class_str} (Confidence: {max(np.squeeze(predictions[0])):.2f})\", loc='left')\n",
        "    ax2.grid(alpha=0.3)\n",
        "    ax2.set_xlim(0.0, 1.0)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 4. Plot Activations ---\n",
        "\n",
        "    if display_activations:\n",
        "        # Visualise activations for each registered layer\n",
        "        for conv_name in conv_names:\n",
        "            # Retrieve stored activations from hooks\n",
        "            layer_activations = activations[conv_name]\n",
        "\n",
        "            # Get number of channels\n",
        "            num_channels = layer_activations.shape[1]\n",
        "\n",
        "            # Display up to 16 feature maps per layer\n",
        "            num_display = min(16, num_channels)\n",
        "\n",
        "            # Calculate grid layout\n",
        "            if num_display <= 8:\n",
        "                rows, cols = 1, num_display\n",
        "                figsize = (18, 3)\n",
        "            else:\n",
        "                rows, cols = 2, 8\n",
        "                figsize = (18, 5)\n",
        "\n",
        "            # Create subplot grid\n",
        "            fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "\n",
        "            # Flatten axes array for easier indexing\n",
        "            if num_display > 1:\n",
        "                axes = axes.flatten() if rows > 1 or cols > 1 else [axes]\n",
        "            else:\n",
        "                axes = [axes]\n",
        "\n",
        "            # Plot each activation map\n",
        "            for i in range(num_display):\n",
        "                ax = axes[i]\n",
        "                activation_map = layer_activations[0, i].cpu().numpy()\n",
        "                ax.imshow(activation_map, cmap='bone', vmin=np.min(activation_map), vmax=np.max(activation_map))\n",
        "                ax.axis('off')\n",
        "                if i == 0:\n",
        "                    ax.set_title(f'{conv_name} activations', loc='left')\n",
        "\n",
        "            # Hide unused subplots\n",
        "            for i in range(num_display, len(axes)):\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "qhm7MxnzWUgv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store layer activations via forward hooks\n",
        "activations = {}\n",
        "\n",
        "# Visualise model predictions and internal representations\n",
        "# Set display_all_conv_layers=True to show all conv layers, False for only last conv of each block\n",
        "visualize(cnn_model, X_val, y_val, unique_labels, display_activations=True, display_all_conv_layers=False)"
      ],
      "metadata": {
        "id": "Rbqg_LFiU2_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è **Deeper CNN**"
      ],
      "metadata": {
        "id": "AmSPhwjVNmQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Architecture parameters\n",
        "# Number of convolutional blocks\n",
        "NUM_BLOCKS = 3\n",
        "\n",
        "# Number of conv layers per block\n",
        "CONVS_PER_BLOCK = 2\n",
        "\n",
        "# Use strided convolutions instead of pooling\n",
        "USE_STRIDE = False\n",
        "\n",
        "# Stride value when USE_STRIDE is True\n",
        "STRIDE_VALUE = 2\n",
        "\n",
        "# Padding size\n",
        "PADDING_SIZE = 1\n",
        "\n",
        "# Pooling size when USE_STRIDE is False\n",
        "POOL_SIZE = 2\n",
        "\n",
        "# Number of channels in first block\n",
        "INITIAL_CHANNELS = 32\n",
        "\n",
        "# Channel multiplication factor between blocks\n",
        "CHANNEL_MULTIPLIER = 2\n",
        "\n",
        "print(\"Num Blocks:\", NUM_BLOCKS)\n",
        "print(\"Convs per Block:\", CONVS_PER_BLOCK)\n",
        "print(\"Use Stride:\", USE_STRIDE)\n",
        "print(\"Stride Value:\", STRIDE_VALUE)\n",
        "print(\"Padding Size:\", PADDING_SIZE)\n",
        "print(\"Pool Size:\", POOL_SIZE)\n",
        "print(\"Initial Channels:\", INITIAL_CHANNELS)\n",
        "print(\"Channel Multiplier:\", CHANNEL_MULTIPLIER)"
      ],
      "metadata": {
        "id": "tF4lVv6nWuF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate CNN model and move to computing device (CPU/GPU)\n",
        "deeper_cnn_model = CNN(\n",
        "    input_shape,\n",
        "    num_classes,\n",
        "    num_blocks=NUM_BLOCKS,\n",
        "    convs_per_block=CONVS_PER_BLOCK,\n",
        "    use_stride=USE_STRIDE,\n",
        "    stride_value=STRIDE_VALUE,\n",
        "    padding_size=PADDING_SIZE,\n",
        "    pool_size=POOL_SIZE,\n",
        "    initial_channels=INITIAL_CHANNELS,\n",
        "    channel_multiplier=CHANNEL_MULTIPLIER\n",
        "    ).to(device)\n",
        "\n",
        "# Display model architecture summary\n",
        "summary(deeper_cnn_model, input_size=input_shape)"
      ],
      "metadata": {
        "id": "kWUjv562WuCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up TensorBoard logging and save model architecture\n",
        "experiment_name = \"deeper_cnn\"\n",
        "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
        "x = torch.randn(1, input_shape[0], input_shape[1], input_shape[2]).to(device)\n",
        "writer.add_graph(deeper_cnn_model, x)\n",
        "\n",
        "# Define optimizer with L2 regularization\n",
        "optimizer = torch.optim.AdamW(deeper_cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
        "\n",
        "# Enable mixed precision training for GPU acceleration\n",
        "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
      ],
      "metadata": {
        "id": "kLYJ3xdKWuAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train model and track training history\n",
        "deeper_cnn_model, training_history = fit(\n",
        "    model=deeper_cnn_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    writer=writer,\n",
        "    verbose=1,\n",
        "    experiment_name=\"deeper_cnn\",\n",
        "    patience=20\n",
        "    )\n",
        "\n",
        "# Update best model if current performance is superior\n",
        "if training_history['val_f1'][-1] > best_performance:\n",
        "    best_model = deeper_cnn_model\n",
        "    best_performance = training_history['val_f1'][-1]"
      ],
      "metadata": {
        "id": "8dXoeSgcWt9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Hitory\n",
        "# Create a figure with two side-by-side subplots (two columns)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
        "\n",
        "# Plot of training and validation loss on the first axis\n",
        "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
        "ax1.set_title('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Plot of training and validation accuracy on the second axis\n",
        "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
        "ax2.set_title('F1 Score')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.85)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YGP8NPtwWt7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Confusion Matrix\n",
        "# Collect predictions and ground truth labels\n",
        "val_preds, val_targets = [], []\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions\n",
        "        logits = deeper_cnn_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        val_preds.append(preds)\n",
        "        val_targets.append(yb.numpy())\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "val_preds = np.concatenate(val_preds)\n",
        "val_targets = np.concatenate(val_targets)\n",
        "\n",
        "# Calculate overall validation metrics\n",
        "val_acc = accuracy_score(val_targets, val_preds)\n",
        "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
        "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
        "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
        "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
        "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
        "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
        "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix for detailed error analysis\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix ‚Äî Validation Set')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uR3h89YiWt4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store layer activations via forward hooks\n",
        "activations = {}\n",
        "\n",
        "# Visualise model predictions and internal representations\n",
        "# Set display_all_conv_layers=True to show all conv layers, False for only last conv of each block\n",
        "visualize(deeper_cnn_model, X_val, y_val, unique_labels, display_activations=True, display_all_conv_layers=False)"
      ],
      "metadata": {
        "id": "-T1iT3VYZlwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è **Even Deeper CNN**"
      ],
      "metadata": {
        "id": "ZU8_fEASeHvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Architecture parameters\n",
        "# Number of convolutional blocks\n",
        "NUM_BLOCKS = 4\n",
        "\n",
        "# Number of conv layers per block\n",
        "CONVS_PER_BLOCK = 2\n",
        "\n",
        "# Use strided convolutions instead of pooling\n",
        "USE_STRIDE = False\n",
        "\n",
        "# Stride value when USE_STRIDE is True\n",
        "STRIDE_VALUE = 2\n",
        "\n",
        "# Padding size\n",
        "PADDING_SIZE = 1\n",
        "\n",
        "# Pooling size when USE_STRIDE is False\n",
        "POOL_SIZE = 2\n",
        "\n",
        "# Number of channels in first block\n",
        "INITIAL_CHANNELS = 32\n",
        "\n",
        "# Channel multiplication factor between blocks\n",
        "CHANNEL_MULTIPLIER = 2\n",
        "\n",
        "print(\"Num Blocks:\", NUM_BLOCKS)\n",
        "print(\"Convs per Block:\", CONVS_PER_BLOCK)\n",
        "print(\"Use Stride:\", USE_STRIDE)\n",
        "print(\"Stride Value:\", STRIDE_VALUE)\n",
        "print(\"Padding Size:\", PADDING_SIZE)\n",
        "print(\"Pool Size:\", POOL_SIZE)\n",
        "print(\"Initial Channels:\", INITIAL_CHANNELS)\n",
        "print(\"Channel Multiplier:\", CHANNEL_MULTIPLIER)"
      ],
      "metadata": {
        "id": "JDzSs_7meWI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate CNN model and move to computing device (CPU/GPU)\n",
        "even_deeper_cnn_model = CNN(\n",
        "    input_shape,\n",
        "    num_classes,\n",
        "    num_blocks=NUM_BLOCKS,\n",
        "    convs_per_block=CONVS_PER_BLOCK,\n",
        "    use_stride=USE_STRIDE,\n",
        "    stride_value=STRIDE_VALUE,\n",
        "    padding_size=PADDING_SIZE,\n",
        "    pool_size=POOL_SIZE,\n",
        "    initial_channels=INITIAL_CHANNELS,\n",
        "    channel_multiplier=CHANNEL_MULTIPLIER\n",
        "    ).to(device)\n",
        "\n",
        "# Display model architecture summary\n",
        "summary(even_deeper_cnn_model, input_size=input_shape)"
      ],
      "metadata": {
        "id": "YHFxt_0PehEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up TensorBoard logging and save model architecture\n",
        "experiment_name = \"even_deeper_cnn\"\n",
        "writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
        "x = torch.randn(1, input_shape[0], input_shape[1], input_shape[2]).to(device)\n",
        "writer.add_graph(even_deeper_cnn_model, x)\n",
        "\n",
        "# Define optimizer with L2 regularization\n",
        "optimizer = torch.optim.AdamW(even_deeper_cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
        "\n",
        "# Enable mixed precision training for GPU acceleration\n",
        "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
      ],
      "metadata": {
        "id": "6waTTCWBenah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train model and track training history\n",
        "even_deeper_cnn_model, training_history = fit(\n",
        "    model=even_deeper_cnn_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    writer=writer,\n",
        "    verbose=1,\n",
        "    experiment_name=\"even_deeper_cnn\",\n",
        "    patience=20\n",
        "    )\n",
        "\n",
        "# Update best model if current performance is superior\n",
        "if training_history['val_f1'][-1] > best_performance:\n",
        "    best_model = even_deeper_cnn_model\n",
        "    best_performance = training_history['val_f1'][-1]"
      ],
      "metadata": {
        "id": "btZgPgz3ezh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Hitory\n",
        "# Create a figure with two side-by-side subplots (two columns)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
        "\n",
        "# Plot of training and validation loss on the first axis\n",
        "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
        "ax1.set_title('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Plot of training and validation accuracy on the second axis\n",
        "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
        "ax2.set_title('F1 Score')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.85)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OpYh-0VZfkdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Confusion Matrix\n",
        "# Collect predictions and ground truth labels\n",
        "val_preds, val_targets = [], []\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions\n",
        "        logits = even_deeper_cnn_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        val_preds.append(preds)\n",
        "        val_targets.append(yb.numpy())\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "val_preds = np.concatenate(val_preds)\n",
        "val_targets = np.concatenate(val_targets)\n",
        "\n",
        "# Calculate overall validation metrics\n",
        "val_acc = accuracy_score(val_targets, val_preds)\n",
        "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
        "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
        "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
        "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
        "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
        "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
        "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix for detailed error analysis\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix ‚Äî Validation Set')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xh0p3S1-fqce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store layer activations via forward hooks\n",
        "activations = {}\n",
        "\n",
        "# Visualise model predictions and internal representations\n",
        "# Set display_all_conv_layers=True to show all conv layers, False for only last conv of each block\n",
        "visualize(even_deeper_cnn_model, X_val, y_val, unique_labels, display_activations=True, display_all_conv_layers=False)"
      ],
      "metadata": {
        "id": "5QJr6McdfxJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy TensorBoard logs to accessible location for Colab\n",
        "!rsync -a $current_dir\"/\"$logs_dir/ \"/content/\"$logs_dir/\n",
        "\n",
        "# Launch TensorBoard interface\n",
        "%tensorboard --logdir \"/content/\"$logs_dir"
      ],
      "metadata": {
        "id": "p6L-hVB7pGOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üïπÔ∏è Use the Model - Make Inference"
      ],
      "metadata": {
        "id": "mONvlb-Xlj12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store layer activations via forward hooks\n",
        "activations = {}\n",
        "\n",
        "# Visualise model predictions and internal representations\n",
        "# Set display_all_conv_layers=True to show all conv layers, False for only last conv of each block\n",
        "visualize(best_model, X_test, y_test, unique_labels, display_activations=True, display_all_conv_layers=False)"
      ],
      "metadata": {
        "id": "GBkRhKEwZ4Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect predictions and ground truth labels\n",
        "test_preds, test_targets = [], []\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions\n",
        "        logits = best_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        test_preds.append(preds)\n",
        "        test_targets.append(yb.numpy())\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test_targets = np.concatenate(test_targets)"
      ],
      "metadata": {
        "id": "J5qjscZ8WUeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall test accuracy\n",
        "test_acc = accuracy_score(test_targets, test_preds)\n",
        "test_prec = precision_score(test_targets, test_preds, average='weighted')\n",
        "test_rec = recall_score(test_targets, test_preds, average='weighted')\n",
        "test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
        "print(f\"Accuracy over the test set: {test_acc:.4f}\")\n",
        "print(f\"Precision over the test set: {test_prec:.4f}\")\n",
        "print(f\"Recall over the test set: {test_rec:.4f}\")\n",
        "print(f\"F1 score over the test set: {test_f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix for detailed error analysis\n",
        "cm = confusion_matrix(test_targets, test_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix ‚Äî Test Set')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZVxKUH8kqDyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "##### Connect with us:\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"14\"> **LinkedIn:**  [AIRLab Polimi](https://www.linkedin.com/company/airlab-polimi/)\n",
        "- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"14\"> **Instagram:** [airlab_polimi](https://www.instagram.com/airlab_polimi/)\n",
        "\n",
        "##### Contributors:\n",
        "- **Eugenio Lomurno**: eugenio.lomurno@polimi.it\n",
        "- **Alberto Archetti**: alberto.archetti@polimi.it\n",
        "- **Roberto Basla**: roberto.basla@polimi.it\n",
        "- **Carlo Sgaravatti**: carlo.sgaravatti@polimi.it\n",
        "\n",
        "```\n",
        "   Copyright 2025 Eugenio Lomurno, Alberto Archetti, Roberto Basla, Carlo Sgaravatti\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```\n"
      ],
      "metadata": {
        "id": "xBkwM_3_p3cI"
      }
    }
  ]
}